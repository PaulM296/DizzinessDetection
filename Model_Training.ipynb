{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.applications import InceptionV3\n",
    "from keras.models import Model\n",
    "from keras.layers import Dropout, Input, Flatten, Dense\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 54334 images belonging to 2 classes.\n",
      "Found 13583 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "batch_size = 8;\n",
    "\n",
    "Train_DataSet_Path = r'D:\\Paul\\CHS_Proiect\\Datasets\\Eyes_DataSet\\Train_Dataset'\n",
    "\n",
    "train_data_generator = ImageDataGenerator(rotation_range=0.2, width_shift_range=0.2, height_shift_range=0.2, shear_range=0.2,zoom_range=0.2, rescale=1./255, validation_split=0.2)\n",
    "train_data = train_data_generator.flow_from_directory(Train_DataSet_Path,\n",
    "                                               target_size=(80, 80), batch_size=batch_size, class_mode='categorical',\n",
    "                                               subset='training')\n",
    "validation_data = train_data_generator.flow_from_directory(Train_DataSet_Path,\n",
    "                                                    target_size=(80, 80), batch_size=batch_size, class_mode='categorical',\n",
    "                                                    subset='validation')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 16981 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "Test_DataSet_Path = r'D:\\Paul\\CHS_Proiect\\Datasets\\Eyes_DataSet\\Test_Dataset'\n",
    "\n",
    "test_data_generator = ImageDataGenerator(rescale=1./255)\n",
    "test_data = test_data_generator.flow_from_directory(Test_DataSet_Path,\n",
    "                                             target_size=(80, 80), batch_size=batch_size, class_mode='categorical')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "base_model = InceptionV3(include_top=False, weights= \"imagenet\", input_tensor=Input(shape=(80, 80, 3)))\n",
    "head_model = base_model.output\n",
    "head_model = Flatten()(head_model)\n",
    "head_model = Dense(64, activation=\"relu\")(head_model)\n",
    "head_model = Dropout(0.5)(head_model)\n",
    "head_model = Dense(2, activation='softmax')(head_model)\n",
    "\n",
    "final_model =  Model(inputs=base_model.input, outputs=head_model)\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "checkpoint = ModelCheckpoint(r'D:\\Paul\\CHS_Proiect\\Models\\model.h5', monitor='val_loss', save_best_only=True, verbose=3)\n",
    "earlystop = EarlyStopping(monitor='val_loss', patience=7, verbose=3, restore_best_weights=True)\n",
    "learning_rate = ReduceLROnPlateau(monitor='val_loss', patience=3, verbose=3)\n",
    "callbacks = [checkpoint, earlystop, learning_rate]\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "6791/6791 [==============================] - ETA: 0s - loss: 0.1960 - accuracy: 0.9247\n",
      "Epoch 1: val_loss improved from inf to 0.27306, saving model to D:\\Paul\\CHS_Proiect\\Models\\model.h5\n",
      "6791/6791 [==============================] - 1970s 289ms/step - loss: 0.1960 - accuracy: 0.9247 - val_loss: 0.2731 - val_accuracy: 0.8985 - lr: 0.0010\n",
      "Epoch 2/5\n",
      "6790/6791 [============================>.] - ETA: 0s - loss: 0.1691 - accuracy: 0.9357\n",
      "Epoch 2: val_loss did not improve from 0.27306\n",
      "6791/6791 [==============================] - 1411s 208ms/step - loss: 0.1691 - accuracy: 0.9358 - val_loss: 0.2733 - val_accuracy: 0.8950 - lr: 0.0010\n",
      "Epoch 3/5\n",
      "6791/6791 [==============================] - ETA: 0s - loss: 0.1583 - accuracy: 0.9404\n",
      "Epoch 3: val_loss improved from 0.27306 to 0.25681, saving model to D:\\Paul\\CHS_Proiect\\Models\\model.h5\n",
      "6791/6791 [==============================] - 432s 64ms/step - loss: 0.1583 - accuracy: 0.9404 - val_loss: 0.2568 - val_accuracy: 0.9053 - lr: 0.0010\n",
      "Epoch 4/5\n",
      "6791/6791 [==============================] - ETA: 0s - loss: 0.1543 - accuracy: 0.9426\n",
      "Epoch 4: val_loss improved from 0.25681 to 0.24912, saving model to D:\\Paul\\CHS_Proiect\\Models\\model.h5\n",
      "6791/6791 [==============================] - 438s 64ms/step - loss: 0.1543 - accuracy: 0.9426 - val_loss: 0.2491 - val_accuracy: 0.9015 - lr: 0.0010\n",
      "Epoch 5/5\n",
      "6790/6791 [============================>.] - ETA: 0s - loss: 0.1500 - accuracy: 0.9431\n",
      "Epoch 5: val_loss did not improve from 0.24912\n",
      "6791/6791 [==============================] - 431s 63ms/step - loss: 0.1500 - accuracy: 0.9431 - val_loss: 0.2805 - val_accuracy: 0.8913 - lr: 0.0010\n"
     ]
    },
    {
     "data": {
      "text/plain": "<keras.callbacks.History at 0x12ab88db220>"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_model.compile(loss='categorical_crossentropy', optimizer='Adam',  metrics=['accuracy'])\n",
    "final_model.fit(train_data, steps_per_epoch=train_data.samples//batch_size, validation_data=validation_data, validation_steps=validation_data.samples//batch_size, callbacks=callbacks, epochs=5)  #8 is the batch_size"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6792/6792 [==============================] - 343s 51ms/step - loss: 0.1271 - accuracy: 0.9517\n",
      "[0.12713490426540375, 0.9516876935958862]\n",
      "1698/1698 [==============================] - 87s 51ms/step - loss: 0.2711 - accuracy: 0.8934\n",
      "[0.27109211683273315, 0.8933961391448975]\n",
      "2123/2123 [==============================] - 349s 165ms/step - loss: 0.2867 - accuracy: 0.9130\n",
      "[0.2867225110530853, 0.9130204319953918]\n"
     ]
    }
   ],
   "source": [
    "print(final_model.evaluate(train_data))\n",
    "print(final_model.evaluate(validation_data))\n",
    "print(final_model.evaluate(test_data))"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
