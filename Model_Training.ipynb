{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.applications import InceptionV3\n",
    "from keras.models import Model\n",
    "from keras.layers import Dropout, Input, Flatten, Dense\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 61127 images belonging to 2 classes.\n",
      "Found 15281 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "batch_size = 8;\n",
    "\n",
    "Train_DataSet_Path = r'D:\\Facultate\\Anul4\\Sem1\\CHS\\Datasets\\Eyes_DataSet\\Train_Dataset'\n",
    "\n",
    "train_data_generator = ImageDataGenerator(rotation_range=0.2, width_shift_range=0.2, height_shift_range=0.2, shear_range=0.2,zoom_range=0.2, rescale=1./255, validation_split=0.2)\n",
    "train_data = train_data_generator.flow_from_directory(Train_DataSet_Path,\n",
    "                                               target_size=(80, 80), batch_size=batch_size, class_mode='categorical',\n",
    "                                               subset='training')\n",
    "validation_data = train_data_generator.flow_from_directory(Train_DataSet_Path,\n",
    "                                                    target_size=(80, 80), batch_size=batch_size, class_mode='categorical',\n",
    "                                                    subset='validation')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8490 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "Test_DataSet_Path = r'D:\\Facultate\\Anul4\\Sem1\\CHS\\Datasets\\Eyes_DataSet\\Test_Dataset'\n",
    "\n",
    "test_data_generator = ImageDataGenerator(rescale=1./255)\n",
    "test_data = test_data_generator.flow_from_directory(Test_DataSet_Path,\n",
    "                                             target_size=(80, 80), batch_size=batch_size, class_mode='categorical')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "base_model = InceptionV3(include_top=False, weights= \"imagenet\", input_tensor=Input(shape=(80, 80, 3)))\n",
    "head_model = base_model.output\n",
    "head_model = Flatten()(head_model)\n",
    "head_model = Dense(64, activation=\"relu\")(head_model)\n",
    "head_model = Dropout(0.5)(head_model)\n",
    "head_model = Dense(2, activation='softmax')(head_model)\n",
    "\n",
    "final_model =  Model(inputs=base_model.input, outputs=head_model)\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "checkpoint = ModelCheckpoint(r'D:\\UPT\\Anul IV\\Sem1\\CHS\\Proiect\\Models\\model.h5', monitor='val_loss', save_best_only=True, verbose=3)\n",
    "earlystop = EarlyStopping(monitor='val_loss', patience=7, verbose=3, restore_best_weights=True)\n",
    "learning_rate = ReduceLROnPlateau(monitor='val_loss', patience=3, verbose=3)\n",
    "callbacks = [checkpoint, earlystop, learning_rate]\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "7640/7640 [==============================] - ETA: 0s - loss: 0.2116 - accuracy: 0.9170\n",
      "Epoch 1: val_loss improved from inf to 0.21604, saving model to D:\\UPT\\Anul IV\\Sem1\\CHS\\Proiect\\Models\\model.h5\n",
      "7640/7640 [==============================] - 1087s 142ms/step - loss: 0.2116 - accuracy: 0.9170 - val_loss: 0.2160 - val_accuracy: 0.9124 - lr: 0.0010\n",
      "Epoch 2/5\n",
      "7638/7640 [============================>.] - ETA: 0s - loss: 0.1798 - accuracy: 0.9318\n",
      "Epoch 2: val_loss improved from 0.21604 to 0.20235, saving model to D:\\UPT\\Anul IV\\Sem1\\CHS\\Proiect\\Models\\model.h5\n",
      "7640/7640 [==============================] - 234s 31ms/step - loss: 0.1798 - accuracy: 0.9318 - val_loss: 0.2024 - val_accuracy: 0.9111 - lr: 0.0010\n",
      "Epoch 3/5\n",
      "7640/7640 [==============================] - ETA: 0s - loss: 0.1731 - accuracy: 0.9341\n",
      "Epoch 3: val_loss improved from 0.20235 to 0.18114, saving model to D:\\UPT\\Anul IV\\Sem1\\CHS\\Proiect\\Models\\model.h5\n",
      "7640/7640 [==============================] - 241s 32ms/step - loss: 0.1731 - accuracy: 0.9341 - val_loss: 0.1811 - val_accuracy: 0.9256 - lr: 0.0010\n",
      "Epoch 4/5\n",
      "7640/7640 [==============================] - ETA: 0s - loss: 0.1653 - accuracy: 0.9380\n",
      "Epoch 4: val_loss did not improve from 0.18114\n",
      "7640/7640 [==============================] - 248s 32ms/step - loss: 0.1653 - accuracy: 0.9380 - val_loss: 0.2012 - val_accuracy: 0.9194 - lr: 0.0010\n",
      "Epoch 5/5\n",
      "7640/7640 [==============================] - ETA: 0s - loss: 0.1627 - accuracy: 0.9386\n",
      "Epoch 5: val_loss did not improve from 0.18114\n",
      "7640/7640 [==============================] - 247s 32ms/step - loss: 0.1627 - accuracy: 0.9386 - val_loss: 0.2090 - val_accuracy: 0.9190 - lr: 0.0010\n"
     ]
    },
    {
     "data": {
      "text/plain": "<keras.callbacks.History at 0x218e934e400>"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_model.compile(loss='categorical_crossentropy', optimizer='Adam',  metrics=['accuracy'])\n",
    "final_model.fit(train_data, steps_per_epoch=train_data.samples//batch_size, validation_data=validation_data, validation_steps=validation_data.samples//batch_size, callbacks=callbacks, epochs=5)  #8 is the batch_size"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7641/7641 [==============================] - 197s 26ms/step - loss: 0.1388 - accuracy: 0.9456\n",
      "[0.13883282244205475, 0.9455723166465759]\n",
      "1911/1911 [==============================] - 46s 24ms/step - loss: 0.2090 - accuracy: 0.9172\n",
      "[0.20902425050735474, 0.9172174334526062]\n",
      "1062/1062 [==============================] - 26s 25ms/step - loss: 0.3270 - accuracy: 0.9000\n",
      "[0.32696133852005005, 0.8999999761581421]\n"
     ]
    }
   ],
   "source": [
    "print(final_model.evaluate(train_data))\n",
    "print(final_model.evaluate(validation_data))\n",
    "print(final_model.evaluate(test_data))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
